{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Don't truncate columns or rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "pd.set_option('display.width', 0)  # auto-adjust to screen size\n",
    "\n",
    "# Then display your DataFrame\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run name</th>\n",
       "      <th>AIME-test2025-I-o4-mini</th>\n",
       "      <th>AIME-test2025-I-gemini</th>\n",
       "      <th>AIME-test2025-I-o4-mini-8-diverse</th>\n",
       "      <th>AIME-test2025-II-o4-mini</th>\n",
       "      <th>AIME-test2025-II-gemini</th>\n",
       "      <th>AIME-test2025-II-o4-mini-8-diverse</th>\n",
       "      <th>processbench_gsm8k</th>\n",
       "      <th>processbench_math</th>\n",
       "      <th>processbench_olympiadbench</th>\n",
       "      <th>processbench_omnimath</th>\n",
       "      <th>PRM800K_test_stepwise_acc</th>\n",
       "      <th>PRM800K_test_problemwise_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trained token | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.578512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trained clf | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.421488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>token | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.578512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.924355</td>\n",
       "      <td>0.421488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.930914</td>\n",
       "      <td>0.570248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clf | Qwen3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.783559</td>\n",
       "      <td>0.396694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  run name  AIME-test2025-I-o4-mini  AIME-test2025-I-gemini  \\\n",
       "0  trained token | Qwen2.5                      0.8                0.866667   \n",
       "1    trained clf | Qwen2.5                      0.8                0.866667   \n",
       "2          token | Qwen2.5                      0.8                0.866667   \n",
       "3            clf | Qwen2.5                      0.8                0.866667   \n",
       "4                 baseline                      0.8                0.866667   \n",
       "5              clf | Qwen3                      0.8                0.866667   \n",
       "\n",
       "   AIME-test2025-I-o4-mini-8-diverse  AIME-test2025-II-o4-mini  \\\n",
       "0                           0.733333                  0.933333   \n",
       "1                           0.733333                  0.933333   \n",
       "2                           0.733333                  0.933333   \n",
       "3                           0.733333                  0.933333   \n",
       "4                           0.733333                  0.933333   \n",
       "5                           0.733333                  0.933333   \n",
       "\n",
       "   AIME-test2025-II-gemini  AIME-test2025-II-o4-mini-8-diverse  \\\n",
       "0                 0.866667                            0.866667   \n",
       "1                 0.866667                            0.866667   \n",
       "2                 0.866667                            0.866667   \n",
       "3                 0.866667                            0.866667   \n",
       "4                 0.866667                            0.866667   \n",
       "5                 0.866667                            0.866667   \n",
       "\n",
       "   processbench_gsm8k  processbench_math  processbench_olympiadbench  \\\n",
       "0              0.5000              0.500                       0.500   \n",
       "1              0.5000              0.500                       0.500   \n",
       "2              0.5000              0.500                       0.500   \n",
       "3              0.5225              0.512                       0.513   \n",
       "4              0.6525              0.680                       0.614   \n",
       "5              0.5025              0.504                       0.499   \n",
       "\n",
       "   processbench_omnimath  PRM800K_test_stepwise_acc  \\\n",
       "0                  0.500                   0.040227   \n",
       "1                  0.500                   0.959773   \n",
       "2                  0.500                   0.040227   \n",
       "3                  0.515                   0.924355   \n",
       "4                  0.589                   0.930914   \n",
       "5                  0.504                   0.783559   \n",
       "\n",
       "   PRM800K_test_problemwise_acc  \n",
       "0                      0.578512  \n",
       "1                      0.421488  \n",
       "2                      0.578512  \n",
       "3                      0.421488  \n",
       "4                      0.570248  \n",
       "5                      0.396694  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "path = \"/home/frozenwolf/Desktop/log_new.txt\"\n",
    "run_names_manual = ['BaselinePRM', 'token | Qwen2.5', 'clf | Qwen2.5', 'token | Qwen3', 'clf | Qwen3', 'trained | token | Qwen2.5', 'trained| clf | Qwen2.5']\n",
    "\n",
    "import re\n",
    "\n",
    "# Replace with your actual log input string or file read\n",
    "with open(path) as f:\n",
    "    log_text = f.read()\n",
    "\n",
    "# 1. Extract all RUN names\n",
    "run_names = re.findall(r\"Running:\\s*(.*)\", log_text)\n",
    "\n",
    "# 2. Extract all ProcessBench entries (dataset + accuracy)\n",
    "processbench_entries = re.findall(\n",
    "    r\"Dataset:\\s*(\\w+).*?Problem-wise Metrics:\\s*\\{[^}]*?'Accuracy':\\s*([0-9.]+)\",\n",
    "    log_text,\n",
    "    re.DOTALL,\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Extract all PRM step-wise & problem-wise accuracies\n",
    "prm_stepwise_accuracies = re.findall(\n",
    "    r\"Step-wise Metrics:\\s*\\{[^}]*?'Accuracy':\\s*([0-9.]+)\", log_text\n",
    ")\n",
    "prm_problemwise_accuracies = re.findall(\n",
    "    r\"Step-wise Metrics: \\{[^}]*?\\}\\s*Problem-wise Metrics:\\s*\\{[^}]*?'Accuracy':\\s*([0-9.]+)\",\n",
    "    log_text\n",
    ")\n",
    "\n",
    "# 4. Extract all AIME entries (model_path, dataset, score)\n",
    "aime_entries = re.findall(\n",
    "    r\"Model\\s+(.*?)\\s+on dataset\\s+(.*?)\\s+has score\\s+([0-9.]+)\", log_text\n",
    ")\n",
    "\n",
    "# # --- Display Results ---\n",
    "\n",
    "# print(\"== RUN Names ==\")\n",
    "# for r in run_names:\n",
    "#     print(r)\n",
    "\n",
    "# print(\"\\n== ProcessBench ==\")\n",
    "# for dataset, acc in processbench_entries:\n",
    "#     print(f\"{dataset}: {acc}\")\n",
    "\n",
    "# print(\"\\n== PRM ==\")\n",
    "# print(f\"Step-wise Accuracies: {prm_stepwise_accuracies}\")\n",
    "# print(f\"Problem-wise Accuracies: {prm_problemwise_accuracies}\")\n",
    "\n",
    "# print(\"\\n== AIME ==\")\n",
    "# for model, dataset, score in aime_entries:\n",
    "#     model_name = model.split(\"/\")[-1]\n",
    "#     print(f\"{dataset} | {model_name}: {score}\")\n",
    "\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "# --- Group helpers ---\n",
    "def chunked(iterable, size):\n",
    "    it = iter(iterable)\n",
    "    return list(iter(lambda: list(islice(it, size)), []))\n",
    "\n",
    "# --- Grouped Entries ---\n",
    "aime_groups = chunked(aime_entries, 6)\n",
    "processbench_groups = chunked(processbench_entries, 4)\n",
    "prm_stepwise = prm_stepwise_accuracies\n",
    "prm_problemwise = prm_problemwise_accuracies\n",
    "\n",
    "# --- Sanity Check ---\n",
    "num_rows = min(len(aime_groups), len(processbench_groups), len(prm_stepwise))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create structured rows\n",
    "table_rows = []\n",
    "for i in range(num_rows):\n",
    "    row = {}\n",
    "\n",
    "    # --- AIME (flatten into columns like aime_1_dataset, aime_1_model, aime_1_score, ...)\n",
    "    for j, (model, dataset, score) in enumerate(aime_groups[i], 1):\n",
    "        model_name = model.split(\"/\")[-1]\n",
    "        row[f\"AIME-{dataset}-{model_name}\"] = float(score)\n",
    "\n",
    "    # --- ProcessBench (math, olympiadbench, omnimath expected)\n",
    "    for dataset, acc in processbench_groups[i]:\n",
    "        row[f\"processbench_{dataset.lower()}\"] = float(acc)\n",
    "\n",
    "    # --- PRM\n",
    "    row[\"PRM800K_test_stepwise_acc\"] = float(prm_stepwise[i])\n",
    "    row[\"PRM800K_test_problemwise_acc\"] = float(prm_problemwise[i])\n",
    "\n",
    "    table_rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(table_rows)\n",
    "run_names[0] = \"trained token | Qwen2.5\"\n",
    "run_names[1] = \"trained clf | Qwen2.5\"\n",
    "df.insert(0, \"run name\",run_names)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained token | Qwen2.5',\n",
       " 'trained clf | Qwen2.5',\n",
       " 'token | Qwen2.5',\n",
       " 'clf | Qwen2.5',\n",
       " 'baseline',\n",
       " 'clf | Qwen3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 6, 6, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processbench_entries), len(prm_stepwise_accuracies), len(prm_problemwise_accuracies), len(aime_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 8, 8, 54)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processbench_entries), len(aime_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIME-test2025-I-o4-mini</th>\n",
       "      <th>AIME-test2025-I-gemini</th>\n",
       "      <th>AIME-test2025-I-o4-mini-8-diverse</th>\n",
       "      <th>AIME-test2025-II-o4-mini</th>\n",
       "      <th>AIME-test2025-II-gemini</th>\n",
       "      <th>AIME-test2025-II-o4-mini-8-diverse</th>\n",
       "      <th>processbench_gsm8k</th>\n",
       "      <th>processbench_math</th>\n",
       "      <th>processbench_olympiadbench</th>\n",
       "      <th>processbench_omnimath</th>\n",
       "      <th>PRM800K_test_stepwise_acc</th>\n",
       "      <th>PRM800K_test_problemwise_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.578512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.421488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.578512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.924355</td>\n",
       "      <td>0.421488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.930914</td>\n",
       "      <td>0.570248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.783559</td>\n",
       "      <td>0.396694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.617840</td>\n",
       "      <td>0.247934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.7575</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.678181</td>\n",
       "      <td>0.264463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AIME-test2025-I-o4-mini  AIME-test2025-I-gemini  \\\n",
       "0                      0.8                0.866667   \n",
       "1                      0.8                0.866667   \n",
       "2                      0.8                0.866667   \n",
       "3                      0.8                0.866667   \n",
       "4                      0.8                0.866667   \n",
       "5                      0.8                0.866667   \n",
       "6                      0.8                0.866667   \n",
       "7                      0.8                0.866667   \n",
       "\n",
       "   AIME-test2025-I-o4-mini-8-diverse  AIME-test2025-II-o4-mini  \\\n",
       "0                           0.733333                  0.933333   \n",
       "1                           0.733333                  0.933333   \n",
       "2                           0.733333                  0.933333   \n",
       "3                           0.733333                  0.933333   \n",
       "4                           0.733333                  0.933333   \n",
       "5                           0.733333                  0.933333   \n",
       "6                           0.733333                  0.933333   \n",
       "7                           0.733333                  0.933333   \n",
       "\n",
       "   AIME-test2025-II-gemini  AIME-test2025-II-o4-mini-8-diverse  \\\n",
       "0                 0.866667                            0.866667   \n",
       "1                 0.866667                            0.866667   \n",
       "2                 0.866667                            0.866667   \n",
       "3                 0.866667                            0.866667   \n",
       "4                 0.866667                            0.866667   \n",
       "5                 0.866667                            0.866667   \n",
       "6                 0.866667                            0.866667   \n",
       "7                 0.866667                            0.866667   \n",
       "\n",
       "   processbench_gsm8k  processbench_math  processbench_olympiadbench  \\\n",
       "0              0.5000              0.500                       0.500   \n",
       "1              0.5000              0.500                       0.500   \n",
       "2              0.5000              0.500                       0.500   \n",
       "3              0.5225              0.512                       0.513   \n",
       "4              0.6525              0.680                       0.614   \n",
       "5              0.5025              0.504                       0.499   \n",
       "6              0.7375              0.700                       0.640   \n",
       "7              0.7575              0.700                       0.651   \n",
       "\n",
       "   processbench_omnimath  PRM800K_test_stepwise_acc  \\\n",
       "0                  0.500                   0.040227   \n",
       "1                  0.500                   0.959773   \n",
       "2                  0.500                   0.040227   \n",
       "3                  0.515                   0.924355   \n",
       "4                  0.589                   0.930914   \n",
       "5                  0.504                   0.783559   \n",
       "6                  0.601                   0.617840   \n",
       "7                    NaN                   0.678181   \n",
       "\n",
       "   PRM800K_test_problemwise_acc  \n",
       "0                      0.578512  \n",
       "1                      0.421488  \n",
       "2                      0.578512  \n",
       "3                      0.421488  \n",
       "4                      0.570248  \n",
       "5                      0.396694  \n",
       "6                      0.247934  \n",
       "7                      0.264463  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained token | Qwen2.5',\n",
       " 'trained clf | Qwen2.5',\n",
       " 'token | Qwen2.5',\n",
       " 'clf | Qwen2.5',\n",
       " 'baseline',\n",
       " 'clf | Qwen3',\n",
       " 'qwen2.5-7B_clf_acc8_scratch_newtoken_whole-sky-243',\n",
       " 'qwen2.5-7B_token_acc1_scratch_newtoken_leafy-morning-242',\n",
       " 'qwen2.5-7B_clf_acc8_baseline_newtoken_silver-dawn-238']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6, 24)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prm_problemwise_accuracies), len(prm_stepwise_accuracies), len(processbench_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.5785123966942148',\n",
       " '0.4214876033057851',\n",
       " '0.5785123966942148',\n",
       " '0.4214876033057851',\n",
       " '0.5702479338842975',\n",
       " '0.39669421487603307']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm_problemwise_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== AIME Table ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_names</th>\n",
       "      <th>test2025-I_o4-mini</th>\n",
       "      <th>test2025-I_gemini</th>\n",
       "      <th>test2025-I_o4-mini-8-diverse</th>\n",
       "      <th>test2025-II_o4-mini</th>\n",
       "      <th>test2025-II_gemini</th>\n",
       "      <th>test2025-II_o4-mini-8-diverse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trained token | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trained clf | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>token | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clf | Qwen3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 run_names  test2025-I_o4-mini  test2025-I_gemini  \\\n",
       "0  trained token | Qwen2.5                 0.8           0.866667   \n",
       "1    trained clf | Qwen2.5                 0.8           0.866667   \n",
       "2          token | Qwen2.5                 0.8           0.866667   \n",
       "3            clf | Qwen2.5                 0.8           0.866667   \n",
       "4                 baseline                 0.8           0.866667   \n",
       "5              clf | Qwen3                 0.8           0.866667   \n",
       "\n",
       "   test2025-I_o4-mini-8-diverse  test2025-II_o4-mini  test2025-II_gemini  \\\n",
       "0                      0.733333             0.933333            0.866667   \n",
       "1                      0.733333             0.933333            0.866667   \n",
       "2                      0.733333             0.933333            0.866667   \n",
       "3                      0.733333             0.933333            0.866667   \n",
       "4                      0.733333             0.933333            0.866667   \n",
       "5                      0.733333             0.933333            0.866667   \n",
       "\n",
       "   test2025-II_o4-mini-8-diverse  \n",
       "0                       0.866667  \n",
       "1                       0.866667  \n",
       "2                       0.866667  \n",
       "3                       0.866667  \n",
       "4                       0.866667  \n",
       "5                       0.866667  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AIME Table\n",
    "aime_data = []\n",
    "for group in aime_groups:\n",
    "    row = {}\n",
    "    for model, dataset, score in group:\n",
    "        model_name = model.split(\"/\")[-1]\n",
    "        col_name = f\"{dataset}_{model_name}\"\n",
    "        row[col_name] = float(score)\n",
    "    aime_data.append(row)\n",
    "\n",
    "df_aime = pd.DataFrame(aime_data)\n",
    "df_aime.insert(0, 'run_names', run_names)\n",
    "print(\"== AIME Table ==\")\n",
    "df_aime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Final AIME Table ==\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">test2025-I</th>\n",
       "      <th colspan=\"3\" halign=\"left\">test2025-II</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>run_names</th>\n",
       "      <th>o4-mini</th>\n",
       "      <th>gemini</th>\n",
       "      <th>o4-mini-8-diverse</th>\n",
       "      <th>o4-mini</th>\n",
       "      <th>gemini</th>\n",
       "      <th>o4-mini-8-diverse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trained token | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trained clf | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>token | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf | Qwen2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clf | Qwen3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model - pass@16</td>\n",
       "      <td></td>\n",
       "      <td>14/15 = 0.9333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14/15 = 0.9333</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model - pass@8</td>\n",
       "      <td>14/15 = 0.9333</td>\n",
       "      <td>13.9580/15 = 0.9305</td>\n",
       "      <td>13/15 = 0.8667</td>\n",
       "      <td>15/15 = 1.0000</td>\n",
       "      <td>13.9872/15 = 0.9325</td>\n",
       "      <td>15/15 = 1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model - consensus</td>\n",
       "      <td>13/15 = 0.8667</td>\n",
       "      <td>12/15 = 0.8000</td>\n",
       "      <td>13/15 = 0.8667</td>\n",
       "      <td>13/15 = 0.8667</td>\n",
       "      <td>13/15 = 0.8667</td>\n",
       "      <td>14/15 = 0.9333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model - pass@1</td>\n",
       "      <td>11.75/15 = 0.7833</td>\n",
       "      <td>12.5/15 = 0.8333</td>\n",
       "      <td>10.875/15 = 0.7250</td>\n",
       "      <td>12.375/15 = 0.8250</td>\n",
       "      <td>13.0625/15 = 0.8708</td>\n",
       "      <td>13.375/15 = 0.8917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   test2025-I                       \\\n",
       "                 run_names            o4-mini               gemini   \n",
       "0  trained token | Qwen2.5                0.8             0.866667   \n",
       "1    trained clf | Qwen2.5                0.8             0.866667   \n",
       "2          token | Qwen2.5                0.8             0.866667   \n",
       "3            clf | Qwen2.5                0.8             0.866667   \n",
       "4                 baseline                0.8             0.866667   \n",
       "5              clf | Qwen3                0.8             0.866667   \n",
       "6          model - pass@16                          14/15 = 0.9333   \n",
       "7           model - pass@8     14/15 = 0.9333  13.9580/15 = 0.9305   \n",
       "8        model - consensus     13/15 = 0.8667       12/15 = 0.8000   \n",
       "9           model - pass@1  11.75/15 = 0.7833     12.5/15 = 0.8333   \n",
       "\n",
       "                              test2025-II                       \\\n",
       "    o4-mini-8-diverse             o4-mini               gemini   \n",
       "0            0.733333            0.933333             0.866667   \n",
       "1            0.733333            0.933333             0.866667   \n",
       "2            0.733333            0.933333             0.866667   \n",
       "3            0.733333            0.933333             0.866667   \n",
       "4            0.733333            0.933333             0.866667   \n",
       "5            0.733333            0.933333             0.866667   \n",
       "6                                               14/15 = 0.9333   \n",
       "7      13/15 = 0.8667      15/15 = 1.0000  13.9872/15 = 0.9325   \n",
       "8      13/15 = 0.8667      13/15 = 0.8667       13/15 = 0.8667   \n",
       "9  10.875/15 = 0.7250  12.375/15 = 0.8250  13.0625/15 = 0.8708   \n",
       "\n",
       "                       \n",
       "    o4-mini-8-diverse  \n",
       "0            0.866667  \n",
       "1            0.866667  \n",
       "2            0.866667  \n",
       "3            0.866667  \n",
       "4            0.866667  \n",
       "5            0.866667  \n",
       "6                      \n",
       "7      15/15 = 1.0000  \n",
       "8      14/15 = 0.9333  \n",
       "9  13.375/15 = 0.8917  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Append model-level rows to df_aime\n",
    "df_extra = pd.DataFrame({\n",
    "    \"run_names\": [\n",
    "        \"model - pass@16\",\n",
    "        \"model - pass@8\",\n",
    "        \"model - consensus\",\n",
    "        \"model - pass@1\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Define mapping for easy access\n",
    "model_scores = {\n",
    "    \"test2025-II_o4-mini\": [\"\", \"15/15 = 1.0000\", \"13/15 = 0.8667\", \"12.375/15 = 0.8250\"],\n",
    "    \"test2025-II_o4-mini-8-diverse\": [\"\", \"15/15 = 1.0000\", \"14/15 = 0.9333\", \"13.375/15 = 0.8917\"],\n",
    "    \"test2025-II_gemini\": [\"14/15 = 0.9333\", \"13.9872/15 = 0.9325\", \"13/15 = 0.8667\", \"13.0625/15 = 0.8708\"],\n",
    "    \"test2025-I_o4-mini\": [\"\", \"14/15 = 0.9333\", \"13/15 = 0.8667\", \"11.75/15 = 0.7833\"],\n",
    "    \"test2025-I_o4-mini-8-diverse\": [\"\", \"13/15 = 0.8667\", \"13/15 = 0.8667\", \"10.875/15 = 0.7250\"],\n",
    "    \"test2025-I_gemini\": [\"14/15 = 0.9333\", \"13.9580/15 = 0.9305\", \"12/15 = 0.8000\", \"12.5/15 = 0.8333\"],\n",
    "}\n",
    "\n",
    "# Append each metric row\n",
    "for i in range(4):  # 4 metrics\n",
    "    row = {k: v[i] for k, v in model_scores.items()}\n",
    "    df_extra.loc[i, list(row.keys())] = list(row.values())\n",
    "\n",
    "# Combine original + new rows\n",
    "df_aime_with_extra = pd.concat([df_aime, df_extra], ignore_index=True)\n",
    "\n",
    "# Step 2: Convert to MultiIndex\n",
    "run_names = df_aime_with_extra['run_names']\n",
    "df_temp = df_aime_with_extra.drop(columns=['run_names'])\n",
    "\n",
    "multi_cols = []\n",
    "for col in df_temp.columns:\n",
    "    if col.startswith(\"test2025-II\"):\n",
    "        group = \"test2025-II\"\n",
    "    elif col.startswith(\"test2025-I\"):\n",
    "        group = \"test2025-I\"\n",
    "    else:\n",
    "        group = \"Other\"\n",
    "    model = col.split(\"_\")[-1]\n",
    "    multi_cols.append((group, model))\n",
    "\n",
    "df_temp.columns = pd.MultiIndex.from_tuples(multi_cols)\n",
    "df_temp.insert(0, ('', 'run_names'), run_names)\n",
    "\n",
    "# Final table\n",
    "print(\"== Final AIME Table ==\")\n",
    "df_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>run_names</th>\n",
       "      <th colspan=\"8\" halign=\"left\">stepwise</th>\n",
       "      <th colspan=\"8\" halign=\"left\">problemwise</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trained token | Qwen2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2195</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>51</td>\n",
       "      <td>0.578512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trained clf | Qwen2.5</td>\n",
       "      <td>2195</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979473</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421488</td>\n",
       "      <td>0.421488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>token | Qwen2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2195</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>51</td>\n",
       "      <td>0.578512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf | Qwen2.5</td>\n",
       "      <td>2080</td>\n",
       "      <td>58</td>\n",
       "      <td>34</td>\n",
       "      <td>115</td>\n",
       "      <td>0.924355</td>\n",
       "      <td>0.972872</td>\n",
       "      <td>0.947608</td>\n",
       "      <td>0.960074</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421488</td>\n",
       "      <td>0.421488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>2079</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>116</td>\n",
       "      <td>0.930914</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.947153</td>\n",
       "      <td>0.963392</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clf | Qwen3</td>\n",
       "      <td>1784</td>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>411</td>\n",
       "      <td>0.783559</td>\n",
       "      <td>0.955032</td>\n",
       "      <td>0.812756</td>\n",
       "      <td>0.878169</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.557576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 run_names stepwise                                    \\\n",
       "                                 TP  FP  TN    FN  Accuracy Precision   \n",
       "0  trained token | Qwen2.5        0   0  92  2195  0.040227  0.000000   \n",
       "1    trained clf | Qwen2.5     2195  92   0     0  0.959773  0.959773   \n",
       "2          token | Qwen2.5        0   0  92  2195  0.040227  0.000000   \n",
       "3            clf | Qwen2.5     2080  58  34   115  0.924355  0.972872   \n",
       "4                 baseline     2079  42  50   116  0.930914  0.980198   \n",
       "5              clf | Qwen3     1784  84   8   411  0.783559  0.955032   \n",
       "\n",
       "                      problemwise                                            \\\n",
       "     Recall        F1          TP  FP  TN  FN  Accuracy Precision    Recall   \n",
       "0  0.000000  0.000000           0   0  70  51  0.578512  0.000000  0.000000   \n",
       "1  1.000000  0.979473          51  70   0   0  0.421488  0.421488  1.000000   \n",
       "2  0.000000  0.000000           0   0  70  51  0.578512  0.000000  0.000000   \n",
       "3  0.947608  0.960074          51  70   0   0  0.421488  0.421488  1.000000   \n",
       "4  0.947153  0.963392          32  33  37  19  0.570248  0.492308  0.627451   \n",
       "5  0.812756  0.878169          46  68   2   5  0.396694  0.403509  0.901961   \n",
       "\n",
       "             \n",
       "         F1  \n",
       "0  0.000000  \n",
       "1  0.593023  \n",
       "2  0.000000  \n",
       "3  0.593023  \n",
       "4  0.551724  \n",
       "5  0.557576  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all full PRM metrics\n",
    "prm_stepwise_full = re.findall(\n",
    "    r\"Step-wise Metrics:\\s*\\{([^}]+)\\}\", log_text\n",
    ")\n",
    "prm_problemwise_full = re.findall(\n",
    "    r\"Step-wise Metrics:\\s*\\{[^}]*?\\}\\s*Problem-wise Metrics:\\s*\\{([^}]*)\\}\",\n",
    "    log_text\n",
    ")\n",
    "# Extract all full ProcessBench metrics\n",
    "processbench_full = re.findall(\n",
    "    r\"Dataset:\\s*(\\w+).*?Problem-wise Metrics:\\s*\\{([^}]+)\\}\",\n",
    "    log_text,\n",
    "    re.DOTALL,\n",
    ")\n",
    "\n",
    "import ast\n",
    "\n",
    "# Parse PRM metrics\n",
    "parsed_prm_stepwise = [ast.literal_eval(\"{\" + entry + \"}\") for entry in prm_stepwise_full]\n",
    "parsed_prm_problemwise = [ast.literal_eval(\"{\" + entry + \"}\") for entry in prm_problemwise_full]\n",
    "\n",
    "# Parse ProcessBench metrics\n",
    "processbench_by_dataset = {}\n",
    "for dataset, metrics_str in processbench_full:\n",
    "    metrics = ast.literal_eval(\"{\" + metrics_str + \"}\")\n",
    "    if dataset not in processbench_by_dataset:\n",
    "        processbench_by_dataset[dataset] = []\n",
    "    processbench_by_dataset[dataset].append(metrics)\n",
    "\n",
    "\n",
    "# Multi-indexed DataFrame: PRM\n",
    "prm_rows = []\n",
    "for sw, pw in zip(parsed_prm_stepwise, parsed_prm_problemwise):\n",
    "    row = {\n",
    "        (\"stepwise\", k): v for k, v in sw.items()\n",
    "    }\n",
    "    row.update({\n",
    "        (\"problemwise\", k): v for k, v in pw.items()\n",
    "    })\n",
    "    prm_rows.append(row)\n",
    "\n",
    "df_prm_full = pd.DataFrame(prm_rows)\n",
    "df_prm_full.columns = pd.MultiIndex.from_tuples(df_prm_full.columns)\n",
    "df_prm_full\n",
    "\n",
    "df_prm_full.insert(0, 'run_names', run_names)\n",
    "df_prm_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>run_names</th>\n",
       "      <th colspan=\"8\" halign=\"left\">gsm8k</th>\n",
       "      <th colspan=\"8\" halign=\"left\">math</th>\n",
       "      <th colspan=\"8\" halign=\"left\">olympiadbench</th>\n",
       "      <th colspan=\"8\" halign=\"left\">omnimath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trained token | Qwen2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trained clf | Qwen2.5</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>token | Qwen2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf | Qwen2.5</td>\n",
       "      <td>200</td>\n",
       "      <td>191</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.511509</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.676819</td>\n",
       "      <td>496</td>\n",
       "      <td>484</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.506122</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.670270</td>\n",
       "      <td>492</td>\n",
       "      <td>479</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.506694</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.668933</td>\n",
       "      <td>486</td>\n",
       "      <td>471</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.507837</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.667124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>199</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.590504</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.741155</td>\n",
       "      <td>476</td>\n",
       "      <td>296</td>\n",
       "      <td>204</td>\n",
       "      <td>24</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.616580</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.748428</td>\n",
       "      <td>474</td>\n",
       "      <td>360</td>\n",
       "      <td>140</td>\n",
       "      <td>26</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.568345</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.710645</td>\n",
       "      <td>456</td>\n",
       "      <td>367</td>\n",
       "      <td>133</td>\n",
       "      <td>44</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.554070</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.689342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clf | Qwen3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>492</td>\n",
       "      <td>488</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>499</td>\n",
       "      <td>500</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>498</td>\n",
       "      <td>494</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.023622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 run_names gsm8k                                           \\\n",
       "                              TP   FP   TN   FN Accuracy Precision Recall   \n",
       "0  trained token | Qwen2.5     0    0  200  200   0.5000  0.000000  0.000   \n",
       "1    trained clf | Qwen2.5   200  200    0    0   0.5000  0.500000  1.000   \n",
       "2          token | Qwen2.5     0    0  200  200   0.5000  0.000000  0.000   \n",
       "3            clf | Qwen2.5   200  191    9    0   0.5225  0.511509  1.000   \n",
       "4                 baseline   199  138   62    1   0.6525  0.590504  0.995   \n",
       "5              clf | Qwen3     4    3  197  196   0.5025  0.571429  0.020   \n",
       "\n",
       "            math                                                     \\\n",
       "         F1   TP   FP   TN   FN Accuracy Precision Recall        F1   \n",
       "0  0.000000    0    0  500  500    0.500  0.000000  0.000  0.000000   \n",
       "1  0.666667  500  500    0    0    0.500  0.500000  1.000  0.666667   \n",
       "2  0.000000    0    0  500  500    0.500  0.000000  0.000  0.000000   \n",
       "3  0.676819  496  484   16    4    0.512  0.506122  0.992  0.670270   \n",
       "4  0.741155  476  296  204   24    0.680  0.616580  0.952  0.748428   \n",
       "5  0.038647   12    8  492  488    0.504  0.600000  0.024  0.046154   \n",
       "\n",
       "  olympiadbench                                                    omnimath  \\\n",
       "             TP   FP   TN   FN Accuracy Precision Recall        F1       TP   \n",
       "0             0    0  500  500    0.500  0.000000  0.000  0.000000        0   \n",
       "1           500  500    0    0    0.500  0.500000  1.000  0.666667      500   \n",
       "2             0    0  500  500    0.500  0.000000  0.000  0.000000        0   \n",
       "3           492  479   21    8    0.513  0.506694  0.984  0.668933      486   \n",
       "4           474  360  140   26    0.614  0.568345  0.948  0.710645      456   \n",
       "5             0    1  499  500    0.499  0.000000  0.000  0.000000        6   \n",
       "\n",
       "                                                      \n",
       "    FP   TN   FN Accuracy Precision Recall        F1  \n",
       "0    0  500  500    0.500  0.000000  0.000  0.000000  \n",
       "1  500    0    0    0.500  0.500000  1.000  0.666667  \n",
       "2    0  500  500    0.500  0.000000  0.000  0.000000  \n",
       "3  471   29   14    0.515  0.507837  0.972  0.667124  \n",
       "4  367  133   44    0.589  0.554070  0.912  0.689342  \n",
       "5    2  498  494    0.504  0.750000  0.012  0.023622  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-indexed DataFrame: ProcessBench\n",
    "pb_rows = []\n",
    "for i in range(len(next(iter(processbench_by_dataset.values())))):  # number of rows\n",
    "    row = {}\n",
    "    for dataset, metrics_list in processbench_by_dataset.items():\n",
    "        if i < len(metrics_list):\n",
    "            for k, v in metrics_list[i].items():\n",
    "                row[(dataset, k)] = v\n",
    "    pb_rows.append(row)\n",
    "\n",
    "df_processbench_full = pd.DataFrame(pb_rows)\n",
    "df_processbench_full.columns = pd.MultiIndex.from_tuples(df_processbench_full.columns)\n",
    "\n",
    "\n",
    "df_processbench_full.insert(0, 'run_names', run_names)\n",
    "df_processbench_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>run_names</th>\n",
       "      <th colspan=\"6\" halign=\"left\">gsm8k</th>\n",
       "      <th colspan=\"6\" halign=\"left\">math</th>\n",
       "      <th colspan=\"6\" halign=\"left\">olympiadbench</th>\n",
       "      <th colspan=\"6\" halign=\"left\">omnimath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trained token | Qwen2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trained clf | Qwen2.5</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>token | Qwen2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clf | Qwen2.5</td>\n",
       "      <td>200</td>\n",
       "      <td>191</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.676819</td>\n",
       "      <td>496</td>\n",
       "      <td>484</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.670270</td>\n",
       "      <td>492</td>\n",
       "      <td>479</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.668933</td>\n",
       "      <td>486</td>\n",
       "      <td>471</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.667124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>199</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.741155</td>\n",
       "      <td>476</td>\n",
       "      <td>296</td>\n",
       "      <td>204</td>\n",
       "      <td>24</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.748428</td>\n",
       "      <td>474</td>\n",
       "      <td>360</td>\n",
       "      <td>140</td>\n",
       "      <td>26</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.710645</td>\n",
       "      <td>456</td>\n",
       "      <td>367</td>\n",
       "      <td>133</td>\n",
       "      <td>44</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.689342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clf | Qwen3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>492</td>\n",
       "      <td>488</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>499</td>\n",
       "      <td>500</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>498</td>\n",
       "      <td>494</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.023622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 run_names gsm8k                                   math       \\\n",
       "                              TP   FP   TN   FN Accuracy        F1   TP   FP   \n",
       "0  trained token | Qwen2.5     0    0  200  200   0.5000  0.000000    0    0   \n",
       "1    trained clf | Qwen2.5   200  200    0    0   0.5000  0.666667  500  500   \n",
       "2          token | Qwen2.5     0    0  200  200   0.5000  0.000000    0    0   \n",
       "3            clf | Qwen2.5   200  191    9    0   0.5225  0.676819  496  484   \n",
       "4                 baseline   199  138   62    1   0.6525  0.741155  476  296   \n",
       "5              clf | Qwen3     4    3  197  196   0.5025  0.038647   12    8   \n",
       "\n",
       "                               olympiadbench                          \\\n",
       "    TN   FN Accuracy        F1            TP   FP   TN   FN Accuracy   \n",
       "0  500  500    0.500  0.000000             0    0  500  500    0.500   \n",
       "1    0    0    0.500  0.666667           500  500    0    0    0.500   \n",
       "2  500  500    0.500  0.000000             0    0  500  500    0.500   \n",
       "3   16    4    0.512  0.670270           492  479   21    8    0.513   \n",
       "4  204   24    0.680  0.748428           474  360  140   26    0.614   \n",
       "5  492  488    0.504  0.046154             0    1  499  500    0.499   \n",
       "\n",
       "            omnimath                                    \n",
       "         F1       TP   FP   TN   FN Accuracy        F1  \n",
       "0  0.000000        0    0  500  500    0.500  0.000000  \n",
       "1  0.666667      500  500    0    0    0.500  0.666667  \n",
       "2  0.000000        0    0  500  500    0.500  0.000000  \n",
       "3  0.668933      486  471   29   14    0.515  0.667124  \n",
       "4  0.710645      456  367  133   44    0.589  0.689342  \n",
       "5  0.000000        6    2  498  494    0.504  0.023622  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics = [\n",
    "    \"TP\",         # True Positives\n",
    "    \"FP\",         # False Positives\n",
    "    \"TN\",         # True Negatives\n",
    "    \"FN\",         # False Negatives\n",
    "    \"Accuracy\",   # Overall accuracy\n",
    "    \"Precision\",  # Precision = TP / (TP + FP)\n",
    "    \"Recall\",     # Recall = TP / (TP + FN)\n",
    "    \"F1\"          # Harmonic mean of Precision and Recall\n",
    "]\n",
    "\n",
    "# Pick metrics to show\n",
    "selected_metrics = [\n",
    "    \"TP\",         # True Positives\n",
    "    \"FP\",         # False Positives\n",
    "    \"TN\",         # True Negatives\n",
    "    \"FN\",         # False Negatives\n",
    "    \"Accuracy\",   # Overall accuracy\n",
    "    \"F1\"          # Harmonic mean of Precision and Recall\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Filter ProcessBench table\n",
    "filtered_processbench = df_processbench_full.loc[:, df_processbench_full.columns.get_level_values(1).isin(selected_metrics)]\n",
    "\n",
    "\n",
    "\n",
    "filtered_processbench.insert(0, 'run_names', run_names)\n",
    "\n",
    "filtered_processbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Combined Table ===\n",
      "\n",
      "--- Entry 1 ---\n",
      "AIME:\n",
      "  test2025-I | o4-mini: 0.8\n",
      "  test2025-I | gemini: 0.8666666666666667\n",
      "  test2025-I | o4-mini-8-diverse: 0.7333333333333333\n",
      "  test2025-II | o4-mini: 0.9333333333333333\n",
      "  test2025-II | gemini: 0.8666666666666667\n",
      "  test2025-II | o4-mini-8-diverse: 0.8666666666666667\n",
      "ProcessBench:\n",
      "  math: 0.68\n",
      "  olympiadbench: 0.614\n",
      "  omnimath: 0.589\n",
      "PRM:\n",
      "  Step-wise Accuracy: 0.9309138609532138\n",
      "  Problem-wise Accuracy: 0.6525\n",
      "\n",
      "--- Entry 2 ---\n",
      "AIME:\n",
      "  test2025-I | o4-mini: 0.8\n",
      "  test2025-I | gemini: 0.8666666666666667\n",
      "  test2025-I | o4-mini-8-diverse: 0.7333333333333333\n",
      "  test2025-II | o4-mini: 0.9333333333333333\n",
      "  test2025-II | gemini: 0.8666666666666667\n",
      "  test2025-II | o4-mini-8-diverse: 0.8666666666666667\n",
      "ProcessBench:\n",
      "  math: 0.5\n",
      "  olympiadbench: 0.5\n",
      "  omnimath: 0.5\n",
      "PRM:\n",
      "  Step-wise Accuracy: 0.04022737210319195\n",
      "  Problem-wise Accuracy: 0.68\n",
      "\n",
      "--- Entry 3 ---\n",
      "AIME:\n",
      "  test2025-I | o4-mini: 0.8\n",
      "  test2025-I | gemini: 0.8666666666666667\n",
      "  test2025-I | o4-mini-8-diverse: 0.7333333333333333\n",
      "  test2025-II | o4-mini: 0.9333333333333333\n",
      "  test2025-II | gemini: 0.8666666666666667\n",
      "  test2025-II | o4-mini-8-diverse: 0.8666666666666667\n",
      "ProcessBench:\n",
      "  math: 0.526\n",
      "  olympiadbench: 0.531\n",
      "  omnimath: 0.519\n",
      "PRM:\n",
      "  Step-wise Accuracy: 0.8994315697420201\n",
      "  Problem-wise Accuracy: 0.614\n",
      "\n",
      "--- Entry 4 ---\n",
      "AIME:\n",
      "  test2025-I | o4-mini: 0.8\n",
      "  test2025-I | gemini: 0.8666666666666667\n",
      "  test2025-I | o4-mini-8-diverse: 0.7333333333333333\n",
      "  test2025-II | o4-mini: 0.9333333333333333\n",
      "  test2025-II | gemini: 0.8666666666666667\n",
      "  test2025-II | o4-mini-8-diverse: 0.8666666666666667\n",
      "ProcessBench:\n",
      "  math: 0.5\n",
      "  olympiadbench: 0.5\n",
      "  omnimath: 0.5\n",
      "PRM:\n",
      "  Step-wise Accuracy: 0.04022737210319195\n",
      "  Problem-wise Accuracy: 0.589\n",
      "\n",
      "--- Entry 5 ---\n",
      "AIME:\n",
      "  test2025-I | o4-mini: 0.8\n",
      "  test2025-I | gemini: 0.8666666666666667\n",
      "  test2025-I | o4-mini-8-diverse: 0.7333333333333333\n",
      "  test2025-II | o4-mini: 0.9333333333333333\n",
      "  test2025-II | gemini: 0.8666666666666667\n",
      "  test2025-II | o4-mini-8-diverse: 0.8666666666666667\n",
      "ProcessBench:\n",
      "  math: 0.501\n",
      "  olympiadbench: 0.501\n",
      "  omnimath: 0.5\n",
      "PRM:\n",
      "  Step-wise Accuracy: 0.5916047223436817\n",
      "  Problem-wise Accuracy: 0.5702479338842975\n",
      "\n",
      "--- Entry 6 ---\n",
      "AIME:\n",
      "  test2025-I | o4-mini: 0.8\n",
      "  test2025-I | gemini: 0.8666666666666667\n",
      "  test2025-I | o4-mini-8-diverse: 0.7333333333333333\n",
      "  test2025-II | o4-mini: 0.9333333333333333\n",
      "  test2025-II | gemini: 0.8666666666666667\n",
      "  test2025-II | o4-mini-8-diverse: 0.8666666666666667\n",
      "ProcessBench:\n",
      "  math: 0.5\n",
      "  olympiadbench: 0.5\n",
      "  omnimath: 0.5\n",
      "PRM:\n",
      "  Step-wise Accuracy: 0.04022737210319195\n",
      "  Problem-wise Accuracy: 0.5\n",
      "\n",
      "--- Entry 7 ---\n",
      "AIME:\n",
      "  test2025-I | o4-mini: 0.8\n",
      "  test2025-I | gemini: 0.8666666666666667\n",
      "  test2025-I | o4-mini-8-diverse: 0.7333333333333333\n",
      "  test2025-II | o4-mini: 0.9333333333333333\n",
      "  test2025-II | gemini: 0.8666666666666667\n",
      "  test2025-II | o4-mini-8-diverse: 0.8666666666666667\n",
      "ProcessBench:\n",
      "  math: 0.5\n",
      "  olympiadbench: 0.5\n",
      "  omnimath: 0.5\n",
      "PRM:\n",
      "  Step-wise Accuracy: 0.9597726278968081\n",
      "  Problem-wise Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# --- Group helpers ---\n",
    "def chunked(iterable, size):\n",
    "    it = iter(iterable)\n",
    "    return list(iter(lambda: list(islice(it, size)), []))\n",
    "\n",
    "# --- Grouped Entries ---\n",
    "aime_groups = chunked(aime_entries, 6)\n",
    "processbench_groups = chunked(processbench_entries, 3)\n",
    "prm_stepwise = prm_stepwise_accuracies\n",
    "prm_problemwise = prm_problemwise_accuracies\n",
    "\n",
    "# --- Sanity Check ---\n",
    "num_rows = min(len(aime_groups), len(processbench_groups), len(prm_stepwise))\n",
    "\n",
    "# --- Table Output ---\n",
    "print(\"\\n=== Combined Table ===\")\n",
    "for i in range(num_rows):\n",
    "    print(f\"\\n--- Entry {i+1} ---\")\n",
    "\n",
    "    # AIME\n",
    "    print(\"AIME:\")\n",
    "    for model, dataset, score in aime_groups[i]:\n",
    "        model_name = model.split(\"/\")[-1]\n",
    "        print(f\"  {dataset} | {model_name}: {score}\")\n",
    "\n",
    "    # ProcessBench\n",
    "    print(\"ProcessBench:\")\n",
    "    for dataset, acc in processbench_groups[i]:\n",
    "        print(f\"  {dataset}: {acc}\")\n",
    "\n",
    "    # PRM\n",
    "    print(\"PRM:\")\n",
    "    print(f\"  Step-wise Accuracy: {prm_stepwise[i]}\")\n",
    "    print(f\"  Problem-wise Accuracy: {prm_problemwise[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 21, 7, 35)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aime_entries), len(processbench_entries), len(prm_stepwise_accuracies), len(prm_problemwise_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 21, 7, 35)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aime_entries), len(processbench_entries), len(prm_stepwise_accuracies), len(prm_problemwise_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIME-test2025-I-o4-mini</th>\n",
       "      <th>AIME-test2025-I-gemini</th>\n",
       "      <th>AIME-test2025-I-o4-mini-8-diverse</th>\n",
       "      <th>AIME-test2025-II-o4-mini</th>\n",
       "      <th>AIME-test2025-II-gemini</th>\n",
       "      <th>AIME-test2025-II-o4-mini-8-diverse</th>\n",
       "      <th>processbench_math</th>\n",
       "      <th>processbench_olympiadbench</th>\n",
       "      <th>processbench_omnimath</th>\n",
       "      <th>PRM800K_test_stepwise_acc</th>\n",
       "      <th>PRM800K_test_problemwise_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.930914</td>\n",
       "      <td>0.652500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.899432</td>\n",
       "      <td>0.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.591605</td>\n",
       "      <td>0.570248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AIME-test2025-I-o4-mini  AIME-test2025-I-gemini  \\\n",
       "0                      0.8                0.866667   \n",
       "1                      0.8                0.866667   \n",
       "2                      0.8                0.866667   \n",
       "3                      0.8                0.866667   \n",
       "4                      0.8                0.866667   \n",
       "5                      0.8                0.866667   \n",
       "6                      0.8                0.866667   \n",
       "\n",
       "   AIME-test2025-I-o4-mini-8-diverse  AIME-test2025-II-o4-mini  \\\n",
       "0                           0.733333                  0.933333   \n",
       "1                           0.733333                  0.933333   \n",
       "2                           0.733333                  0.933333   \n",
       "3                           0.733333                  0.933333   \n",
       "4                           0.733333                  0.933333   \n",
       "5                           0.733333                  0.933333   \n",
       "6                           0.733333                  0.933333   \n",
       "\n",
       "   AIME-test2025-II-gemini  AIME-test2025-II-o4-mini-8-diverse  \\\n",
       "0                 0.866667                            0.866667   \n",
       "1                 0.866667                            0.866667   \n",
       "2                 0.866667                            0.866667   \n",
       "3                 0.866667                            0.866667   \n",
       "4                 0.866667                            0.866667   \n",
       "5                 0.866667                            0.866667   \n",
       "6                 0.866667                            0.866667   \n",
       "\n",
       "   processbench_math  processbench_olympiadbench  processbench_omnimath  \\\n",
       "0              0.680                       0.614                  0.589   \n",
       "1              0.500                       0.500                  0.500   \n",
       "2              0.526                       0.531                  0.519   \n",
       "3              0.500                       0.500                  0.500   \n",
       "4              0.501                       0.501                  0.500   \n",
       "5              0.500                       0.500                  0.500   \n",
       "6              0.500                       0.500                  0.500   \n",
       "\n",
       "   PRM800K_test_stepwise_acc  PRM800K_test_problemwise_acc  \n",
       "0                   0.930914                      0.652500  \n",
       "1                   0.040227                      0.680000  \n",
       "2                   0.899432                      0.614000  \n",
       "3                   0.040227                      0.589000  \n",
       "4                   0.591605                      0.570248  \n",
       "5                   0.040227                      0.500000  \n",
       "6                   0.959773                      0.500000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create structured rows\n",
    "table_rows = []\n",
    "for i in range(num_rows):\n",
    "    row = {}\n",
    "\n",
    "    # --- AIME (flatten into columns like aime_1_dataset, aime_1_model, aime_1_score, ...)\n",
    "    for j, (model, dataset, score) in enumerate(aime_groups[i], 1):\n",
    "        model_name = model.split(\"/\")[-1]\n",
    "        row[f\"AIME-{dataset}-{model_name}\"] = float(score)\n",
    "\n",
    "    # --- ProcessBench (math, olympiadbench, omnimath expected)\n",
    "    for dataset, acc in processbench_groups[i]:\n",
    "        row[f\"processbench_{dataset.lower()}\"] = float(acc)\n",
    "\n",
    "    # --- PRM\n",
    "    row[\"PRM800K_test_stepwise_acc\"] = float(prm_stepwise[i])\n",
    "    row[\"PRM800K_test_problemwise_acc\"] = float(prm_problemwise[i])\n",
    "\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(table_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BaselinePRM',\n",
       " 'BaselinePRM',\n",
       " 'BaselinePRM',\n",
       " 'proocessbench_myprm_qwen_benchmark.py | token | Qwen2.5',\n",
       " 'myprm_qwen_benchmark.py | token | Qwen2.5',\n",
       " 'aime_myprm_benchmark.py | token | Qwen2.5',\n",
       " 'aime_myprm_benchmark.py | clf | Qwen2.5',\n",
       " 'myprm_qwen_benchmark.py | clf | Qwen2.5',\n",
       " 'proocessbench_myprm_qwen_benchmark.py | clf | Qwen2.5',\n",
       " 'aime_myprm_benchmark.py | token | Qwen3',\n",
       " 'myprm_qwen_benchmark.py | token | Qwen3',\n",
       " 'proocessbench_myprm_qwen_benchmark.py | token | Qwen3',\n",
       " 'aime_myprm_benchmark.py | clf | Qwen3',\n",
       " 'myprm_qwen_benchmark.py | clf | Qwen3',\n",
       " 'proocessbench_myprm_qwen_benchmark.py | clf | Qwen3',\n",
       " 'qwen2.5-7B_token_acc16_baseline_lr1e-4_dropout0',\n",
       " 'qwen2.5-7B_clf_acc8_baseline_lr1e-4_dropout0']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">AIME</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PRM800K</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ProcessBench</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>test2025-II_gemini</th>\n",
       "      <th>test2025-II_o4-mini</th>\n",
       "      <th>test2025-II_o4-mini-8-diverse</th>\n",
       "      <th>test2025-I_gemini</th>\n",
       "      <th>test2025-I_o4-mini</th>\n",
       "      <th>test2025-I_o4-mini-8-diverse</th>\n",
       "      <th>problemwise_acc</th>\n",
       "      <th>stepwise_acc</th>\n",
       "      <th>math</th>\n",
       "      <th>olympiadbench</th>\n",
       "      <th>omnimath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.930914</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.899432</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.591605</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AIME                                                    \\\n",
       "  test2025-II_gemini test2025-II_o4-mini test2025-II_o4-mini-8-diverse   \n",
       "0           0.866667            0.933333                      0.866667   \n",
       "1           0.866667            0.933333                      0.866667   \n",
       "2           0.866667            0.933333                      0.866667   \n",
       "3           0.866667            0.933333                      0.866667   \n",
       "4           0.866667            0.933333                      0.866667   \n",
       "5           0.866667            0.933333                      0.866667   \n",
       "6           0.866667            0.933333                      0.866667   \n",
       "\n",
       "                                                                     \\\n",
       "  test2025-I_gemini test2025-I_o4-mini test2025-I_o4-mini-8-diverse   \n",
       "0          0.866667                0.8                     0.733333   \n",
       "1          0.866667                0.8                     0.733333   \n",
       "2          0.866667                0.8                     0.733333   \n",
       "3          0.866667                0.8                     0.733333   \n",
       "4          0.866667                0.8                     0.733333   \n",
       "5          0.866667                0.8                     0.733333   \n",
       "6          0.866667                0.8                     0.733333   \n",
       "\n",
       "          PRM800K              ProcessBench                         \n",
       "  problemwise_acc stepwise_acc         math olympiadbench omnimath  \n",
       "0        0.652500     0.930914        0.680         0.614    0.589  \n",
       "1        0.680000     0.040227        0.500         0.500    0.500  \n",
       "2        0.614000     0.899432        0.526         0.531    0.519  \n",
       "3        0.589000     0.040227        0.500         0.500    0.500  \n",
       "4        0.570248     0.591605        0.501         0.501    0.500  \n",
       "5        0.500000     0.040227        0.500         0.500    0.500  \n",
       "6        0.500000     0.959773        0.500         0.500    0.500  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table_rows = []\n",
    "run_names = ['BaselinePRM', 'token | Qwen2.5', 'clf | Qwen2.5', 'token | Qwen3', 'clf | Qwen3', 'trained | token | Qwen2.5', 'trained| clf | Qwen2.5']\n",
    "\n",
    "for i in range(num_rows):\n",
    "    row = {}\n",
    "    # AIME\n",
    "    for j, (model, dataset, score) in enumerate(aime_groups[i], 1):\n",
    "        model_name = model.split(\"/\")[-1]\n",
    "        row[(\"AIME\", f\"{dataset}_{model_name}\")] = float(score)\n",
    "\n",
    "    # ProcessBench\n",
    "    for dataset, acc in processbench_groups[i]:\n",
    "        row[(\"ProcessBench\", dataset.lower())] = float(acc)\n",
    "\n",
    "    # PRM800K\n",
    "    row[(\"PRM800K\", \"stepwise_acc\")] = float(prm_stepwise[i])\n",
    "    row[(\"PRM800K\", \"problemwise_acc\")] = float(prm_problemwise[i])\n",
    "\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Create MultiIndex DataFrame\n",
    "df = pd.DataFrame(table_rows)\n",
    "df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "\n",
    "# Optional: Pretty display\n",
    "df = df.sort_index(axis=1, level=0)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>run_names</th>\n",
       "      <th colspan=\"6\" halign=\"left\">AIME</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PRM800K</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ProcessBench</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test2025-II_gemini</th>\n",
       "      <th>test2025-II_o4-mini</th>\n",
       "      <th>test2025-II_o4-mini-8-diverse</th>\n",
       "      <th>test2025-I_gemini</th>\n",
       "      <th>test2025-I_o4-mini</th>\n",
       "      <th>test2025-I_o4-mini-8-diverse</th>\n",
       "      <th>problemwise_acc</th>\n",
       "      <th>stepwise_acc</th>\n",
       "      <th>math</th>\n",
       "      <th>olympiadbench</th>\n",
       "      <th>omnimath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaselinePRM</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.930914</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>token | Qwen2.5</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clf | Qwen2.5</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.899432</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>token | Qwen3</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clf | Qwen3</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.591605</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trained | token | Qwen2.5</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trained| clf | Qwen2.5</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   run_names               AIME                      \\\n",
       "                             test2025-II_gemini test2025-II_o4-mini   \n",
       "0                BaselinePRM           0.866667            0.933333   \n",
       "1            token | Qwen2.5           0.866667            0.933333   \n",
       "2              clf | Qwen2.5           0.866667            0.933333   \n",
       "3              token | Qwen3           0.866667            0.933333   \n",
       "4                clf | Qwen3           0.866667            0.933333   \n",
       "5  trained | token | Qwen2.5           0.866667            0.933333   \n",
       "6     trained| clf | Qwen2.5           0.866667            0.933333   \n",
       "\n",
       "                                                                      \\\n",
       "  test2025-II_o4-mini-8-diverse test2025-I_gemini test2025-I_o4-mini   \n",
       "0                      0.866667          0.866667                0.8   \n",
       "1                      0.866667          0.866667                0.8   \n",
       "2                      0.866667          0.866667                0.8   \n",
       "3                      0.866667          0.866667                0.8   \n",
       "4                      0.866667          0.866667                0.8   \n",
       "5                      0.866667          0.866667                0.8   \n",
       "6                      0.866667          0.866667                0.8   \n",
       "\n",
       "                                       PRM800K              ProcessBench  \\\n",
       "  test2025-I_o4-mini-8-diverse problemwise_acc stepwise_acc         math   \n",
       "0                     0.733333        0.652500     0.930914        0.680   \n",
       "1                     0.733333        0.680000     0.040227        0.500   \n",
       "2                     0.733333        0.614000     0.899432        0.526   \n",
       "3                     0.733333        0.589000     0.040227        0.500   \n",
       "4                     0.733333        0.570248     0.591605        0.501   \n",
       "5                     0.733333        0.500000     0.040227        0.500   \n",
       "6                     0.733333        0.500000     0.959773        0.500   \n",
       "\n",
       "                          \n",
       "  olympiadbench omnimath  \n",
       "0         0.614    0.589  \n",
       "1         0.500    0.500  \n",
       "2         0.531    0.519  \n",
       "3         0.500    0.500  \n",
       "4         0.501    0.500  \n",
       "5         0.500    0.500  \n",
       "6         0.500    0.500  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(0, 'run_names', run_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "ds = load_from_disk(\"../PRM800k_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completions</th>\n",
       "      <th>labels</th>\n",
       "      <th>index</th>\n",
       "      <th>correctness</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>level</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326762</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[To find the greatest common divisor, we need ...</td>\n",
       "      <td>[False]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326763</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[Let's write out the prime factorization of 12.]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326764</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[Let's write the prime factorization for each ...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326765</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[Let's prime factorize 12. 12 is divisible by ...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326766</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[Ok, well let's first find the prime factoriza...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326767 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   prompt  \\\n",
       "0       How many positive two-digit integers leave a r...   \n",
       "1       How many positive two-digit integers leave a r...   \n",
       "2       How many positive two-digit integers leave a r...   \n",
       "3       How many positive two-digit integers leave a r...   \n",
       "4       How many positive two-digit integers leave a r...   \n",
       "...                                                   ...   \n",
       "326762     Find the greatest common divisor of 12 and 20.   \n",
       "326763     Find the greatest common divisor of 12 and 20.   \n",
       "326764     Find the greatest common divisor of 12 and 20.   \n",
       "326765     Find the greatest common divisor of 12 and 20.   \n",
       "326766     Find the greatest common divisor of 12 and 20.   \n",
       "\n",
       "                                              completions  \\\n",
       "0       [So if a number leaves a remainder of 2 when d...   \n",
       "1       [So if a number leaves a remainder of 2 when d...   \n",
       "2       [So if a number leaves a remainder of 2 when d...   \n",
       "3       [So if a number leaves a remainder of 2 when d...   \n",
       "4       [So if a number leaves a remainder of 2 when d...   \n",
       "...                                                   ...   \n",
       "326762  [To find the greatest common divisor, we need ...   \n",
       "326763   [Let's write out the prime factorization of 12.]   \n",
       "326764  [Let's write the prime factorization for each ...   \n",
       "326765  [Let's prime factorize 12. 12 is divisible by ...   \n",
       "326766  [Ok, well let's first find the prime factoriza...   \n",
       "\n",
       "                                                   labels  index  correctness  \\\n",
       "0       [True, True, True, True, True, True, True, Tru...      1            1   \n",
       "1       [True, True, True, True, True, True, True, Tru...      1            1   \n",
       "2       [True, True, True, True, True, True, True, Tru...      1            1   \n",
       "3       [True, True, True, True, True, True, True, Tru...      1            1   \n",
       "4       [True, True, True, True, True, True, True, Tru...      1            1   \n",
       "...                                                   ...    ...          ...   \n",
       "326762                                            [False]  97732            0   \n",
       "326763                                             [True]  97732            0   \n",
       "326764                                             [True]  97732            0   \n",
       "326765                                             [True]  97732            0   \n",
       "326766                                             [True]  97732            0   \n",
       "\n",
       "       answer        subject  level  __index_level_0__  \n",
       "0          12  Number Theory      2                  0  \n",
       "1          12  Number Theory      2                  1  \n",
       "2          12  Number Theory      2                  2  \n",
       "3          12  Number Theory      2                  3  \n",
       "4          12  Number Theory      2                  4  \n",
       "...       ...            ...    ...                ...  \n",
       "326762      4     Prealgebra      2             327693  \n",
       "326763      4     Prealgebra      2             327694  \n",
       "326764      4     Prealgebra      2             327695  \n",
       "326765      4     Prealgebra      2             327696  \n",
       "326766      4     Prealgebra      2             327697  \n",
       "\n",
       "[326767 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### labels column is a list of bools. add them and count\n",
    "count = df['labels'].apply(lambda x: sum(x))\n",
    "total = df['labels'].apply(lambda x: len(x))\n",
    "positive_perc = count / total * 100\n",
    "positive_perc = positive_perc.to_list()\n",
    "from collections import Counter\n",
    "counter = Counter(positive_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "### plot matplotlib counter\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(counter.keys(), counter.values(), color='blue')\n",
    "plt.xlabel('Percentage of Positive Labels')\n",
    "plt.ylabel('Percentage of Positive Labels (%)')\n",
    "plt.title('Percentage of Positive Labels per ID')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.05077349052932"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(positive_perc)/len(positive_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.90428285170461"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(count.to_list()) / sum(total.to_list()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completions</th>\n",
       "      <th>labels</th>\n",
       "      <th>index</th>\n",
       "      <th>correctness</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>level</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n",
       "      <td>[Let's call the price of a pencil p and the pr...</td>\n",
       "      <td>[True, True, True, True, True, False]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n",
       "      <td>[Let's call the price of a pencil p and the pr...</td>\n",
       "      <td>[True, True, True, True, True, False]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n",
       "      <td>[Let's call the price of a pencil p and the pr...</td>\n",
       "      <td>[True, True, True, True, True, False]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n",
       "      <td>[Let's call the price of a pencil p and the pr...</td>\n",
       "      <td>[True, True, True, True, True, False]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Three pencils and a jumbo eraser cost $\\$1.24$...</td>\n",
       "      <td>[Let's call the price of a pencil p and the pr...</td>\n",
       "      <td>[True, True, True, True, True, False]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>The point $(0,0)$ is reflected over the vertic...</td>\n",
       "      <td>[I need to find the coordinates of the final p...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>2710</td>\n",
       "      <td>0</td>\n",
       "      <td>(2,4)</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>2</td>\n",
       "      <td>9951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>The point $(0,0)$ is reflected over the vertic...</td>\n",
       "      <td>[I need to find the coordinates of the final p...</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>2710</td>\n",
       "      <td>0</td>\n",
       "      <td>(2,4)</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>2</td>\n",
       "      <td>9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>The point $(0,0)$ is reflected over the vertic...</td>\n",
       "      <td>[I need to find the coordinates of the final p...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>2710</td>\n",
       "      <td>0</td>\n",
       "      <td>(2,4)</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>2</td>\n",
       "      <td>9953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>The point $(0,0)$ is reflected over the vertic...</td>\n",
       "      <td>[I need to find the coordinates of the final p...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>2710</td>\n",
       "      <td>0</td>\n",
       "      <td>(2,4)</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>2</td>\n",
       "      <td>9954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>The point $(0,0)$ is reflected over the vertic...</td>\n",
       "      <td>[I need to find the coordinates of the final p...</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>2710</td>\n",
       "      <td>0</td>\n",
       "      <td>(2,4)</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>2</td>\n",
       "      <td>9955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9881 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "0     Three pencils and a jumbo eraser cost $\\$1.24$...   \n",
       "1     Three pencils and a jumbo eraser cost $\\$1.24$...   \n",
       "2     Three pencils and a jumbo eraser cost $\\$1.24$...   \n",
       "3     Three pencils and a jumbo eraser cost $\\$1.24$...   \n",
       "4     Three pencils and a jumbo eraser cost $\\$1.24$...   \n",
       "...                                                 ...   \n",
       "9876  The point $(0,0)$ is reflected over the vertic...   \n",
       "9877  The point $(0,0)$ is reflected over the vertic...   \n",
       "9878  The point $(0,0)$ is reflected over the vertic...   \n",
       "9879  The point $(0,0)$ is reflected over the vertic...   \n",
       "9880  The point $(0,0)$ is reflected over the vertic...   \n",
       "\n",
       "                                            completions  \\\n",
       "0     [Let's call the price of a pencil p and the pr...   \n",
       "1     [Let's call the price of a pencil p and the pr...   \n",
       "2     [Let's call the price of a pencil p and the pr...   \n",
       "3     [Let's call the price of a pencil p and the pr...   \n",
       "4     [Let's call the price of a pencil p and the pr...   \n",
       "...                                                 ...   \n",
       "9876  [I need to find the coordinates of the final p...   \n",
       "9877  [I need to find the coordinates of the final p...   \n",
       "9878  [I need to find the coordinates of the final p...   \n",
       "9879  [I need to find the coordinates of the final p...   \n",
       "9880  [I need to find the coordinates of the final p...   \n",
       "\n",
       "                                     labels  index  correctness answer  \\\n",
       "0     [True, True, True, True, True, False]      0            1     29   \n",
       "1     [True, True, True, True, True, False]      0            1     29   \n",
       "2     [True, True, True, True, True, False]      0            1     29   \n",
       "3     [True, True, True, True, True, False]      0            1     29   \n",
       "4     [True, True, True, True, True, False]      0            1     29   \n",
       "...                                     ...    ...          ...    ...   \n",
       "9876                          [True, False]   2710            0  (2,4)   \n",
       "9877                           [True, True]   2710            0  (2,4)   \n",
       "9878                          [True, False]   2710            0  (2,4)   \n",
       "9879                          [True, False]   2710            0  (2,4)   \n",
       "9880                           [True, True]   2710            0  (2,4)   \n",
       "\n",
       "       subject  level  __index_level_0__  \n",
       "0      Algebra      2                  0  \n",
       "1      Algebra      2                  1  \n",
       "2      Algebra      2                  2  \n",
       "3      Algebra      2                  3  \n",
       "4      Algebra      2                  4  \n",
       "...        ...    ...                ...  \n",
       "9876  Geometry      2               9951  \n",
       "9877  Geometry      2               9952  \n",
       "9878  Geometry      2               9953  \n",
       "9879  Geometry      2               9954  \n",
       "9880  Geometry      2               9955  \n",
       "\n",
       "[9881 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dst = ds['test'].to_pandas()\n",
    "dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject\n",
       "Algebra                   2399\n",
       "Intermediate Algebra      2361\n",
       "Number Theory             1437\n",
       "Prealgebra                1258\n",
       "Precalculus               1069\n",
       "Counting & Probability     743\n",
       "Geometry                   614\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def select_top_20(group):\n",
    "    # Ensure label length is available\n",
    "    group = group.copy()\n",
    "    group['label_len'] = group['labels'].apply(len)\n",
    "    \n",
    "    # Get top 10 True correctness with unique prompts\n",
    "    true_rows = (\n",
    "        group[group['correctness'] == True]\n",
    "        .sort_values('label_len', ascending=False)\n",
    "        .drop_duplicates('prompt')\n",
    "        .head(10)\n",
    "    )\n",
    "\n",
    "    # Get top 10 False correctness with unique prompts\n",
    "    false_rows = (\n",
    "        group[group['correctness'] == False]\n",
    "        .sort_values('label_len', ascending=False)\n",
    "        .drop_duplicates('prompt')\n",
    "        .head(10)\n",
    "    )\n",
    "    \n",
    "    return pd.concat([true_rows, false_rows])\n",
    "\n",
    "# Apply this for each subject\n",
    "dst_selected = dst.groupby('subject', group_keys=False).apply(select_top_20)\n",
    "\n",
    "# Optional cleanup\n",
    "dst_selected = dst_selected.drop(columns='label_len').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject\n",
       "Algebra                   20\n",
       "Intermediate Algebra      20\n",
       "Number Theory             19\n",
       "Counting & Probability    18\n",
       "Precalculus               18\n",
       "Geometry                  14\n",
       "Prealgebra                12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_selected['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Algebra\n",
       "1        Algebra\n",
       "2        Algebra\n",
       "3        Algebra\n",
       "4        Algebra\n",
       "          ...   \n",
       "9876    Geometry\n",
       "9877    Geometry\n",
       "9878    Geometry\n",
       "9879    Geometry\n",
       "9880    Geometry\n",
       "Name: subject, Length: 9881, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst['subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correctness\n",
       "0    9523\n",
       "1     358\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst['correctness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def make_step_rewards(logits, token_masks):\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "    probabilities = probabilities * token_masks.unsqueeze(-1)  # bs, seq_len, num_labels\n",
    "\n",
    "    all_scores_res = []\n",
    "    for i in range(probabilities.size(0)):\n",
    "        sample = probabilities[i]  # seq_len, num_labels\n",
    "        positive_probs = sample[sample != 0].view(-1, 2)[:, 1]  # get p(label=1)\n",
    "        all_scores_res.append(positive_probs.cpu().tolist())\n",
    "    return all_scores_res\n",
    "\n",
    "\n",
    "def evaluate_question_stepwise(model, tokenizer, system_prompt, question, stepwise_solution):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "        {\"role\": \"assistant\", \"content\": \"<extra_0>\".join(stepwise_solution) + \"<extra_0>\"},\n",
    "    ]\n",
    "    conversation_str = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    # print(\"Conversation String:\", conversation_str)\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        conversation_str,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    step_sep_id = tokenizer.encode(\"<extra_0>\")[0]\n",
    "    token_masks = (input_ids == step_sep_id)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "        step_rewards = make_step_rewards(outputs[0], token_masks)\n",
    "\n",
    "    return step_rewards[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "class DummyModel:\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.device = torch.device(device)\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        return self\n",
    "\n",
    "    def __call__(self, input_ids):\n",
    "        # Simulate logits: shape [batch_size=1, seq_len, num_labels=2]\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        logits = torch.randn(batch_size, seq_len, 2)  # fake logits\n",
    "        return (logits,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5778879523277283, 0.6447142362594604, 0.6988536715507507, 0.7992584109306335]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-Math-PRM-7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "# model = AutoModel.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     trust_remote_code=True\n",
    "# ).eval()\n",
    "\n",
    "### generate a dmmmy class to simulate the model\n",
    "model = DummyModel(device=\"cpu\").eval()\n",
    "\n",
    "data = {\n",
    "    \"system\": \"Please reason step by step, and put your final answer within \\\\boxed{}.\",\n",
    "    \"query\": \"Sue lives in a fun neighborhood...\",\n",
    "    \"response\": [\n",
    "        \"To find out how many more pink plastic flamingos...\",\n",
    "        \"On Saturday, they take back one third...\",\n",
    "        \"On Sunday, the neighbors add another 18...\",\n",
    "        \"To find the difference, subtract the number of white flamingos...\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "step_rewards = evaluate_question_stepwise(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    system_prompt=data[\"system\"],\n",
    "    question=data[\"query\"],\n",
    "    stepwise_solution=data[\"response\"]\n",
    ")\n",
    "\n",
    "print(step_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_step_pred, all_step_labels, all_problem_correctness, all_problem_pred = [], [], [], []\n",
    "for questions, solutions, step_labels, correctness in zip(\n",
    "    dst_selected['prompt'].tolist(),\n",
    "    dst_selected['completions'].tolist(),\n",
    "    dst_selected['labels'].tolist(),\n",
    "    dst_selected['correctness'].tolist()\n",
    "):\n",
    "    step_rewards = evaluate_question_stepwise(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        system_prompt=\"Please reason step by step, and put your final answer within \\\\boxed{}.\",\n",
    "        question=questions,\n",
    "        stepwise_solution=solutions\n",
    "    )\n",
    "    \n",
    "    all_step_pred+= [1 if i>=0.5 else 0 for i in step_rewards]\n",
    "    all_step_labels+= [1 if i else 0 for i in step_labels.tolist()]\n",
    "    all_problem_correctness+=[correctness]\n",
    "    a = step_rewards[-1]\n",
    "    all_problem_pred+=[1 if a>=0.5 else 0]\n",
    "    # print(f\"Question: {questions}\")\n",
    "    # print(f\"Solutions: {solutions}\")\n",
    "    # print(f\"Step Rewards: {step_rewards}\")\n",
    "    # print(f\"Labels: {step_labels}, Correctness: {correctness}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frozenwolf/miniconda3/envs/prm/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/frozenwolf/miniconda3/envs/prm/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/frozenwolf/Desktop/LLM reasoning/code/DreamPRM/model.py:373: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  accuracy = (TP + TN) / len(labels)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from model import binary_classification_metrics\n",
    "step_metrics = binary_classification_metrics(all_step_pred, all_step_labels)\n",
    "problem_metric = binary_classification_metrics(all_problem_pred, all_problem_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'TP': 1114,\n",
       "  'FP': 42,\n",
       "  'TN': 50,\n",
       "  'FN': 1081,\n",
       "  'Accuracy': 0.5089637079142982,\n",
       "  'Precision': 0.9636678200692042,\n",
       "  'Recall': 0.5075170842824601,\n",
       "  'F1': 0.6648761563712324},\n",
       " {'TP': 23,\n",
       "  'FP': 34,\n",
       "  'TN': 36,\n",
       "  'FN': 28,\n",
       "  'Accuracy': 0.48760330578512395,\n",
       "  'Precision': 0.40350877192982454,\n",
       "  'Recall': 0.45098039215686275,\n",
       "  'F1': 0.42592592592592593})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_metrics, problem_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading aime_outputs/test2025-II/o4-mini/AIME_o4_mini_8_traj_25_II.jsonl with 15 samples\n",
      "Pass@1:  14/15 = 0.9333\n",
      "Consensus (majority voting): 14/15 = 0.9333\n",
      "Pass@1: 14/15 = 0.9333\n",
      "Model aime_outputs/test2025-II/o4-mini on dataset test2025-II has score 0.9333333333333333\n",
      "Loading aime_outputs/test2025-II/o4-mini-8-diverse/AIME_o4_mini_diverse_traj_25_II.jsonl with 15 samples\n",
      "Pass@1:  13/15 = 0.8667\n",
      "Consensus (majority voting): 13/15 = 0.8667\n",
      "Pass@1: 13/15 = 0.8667\n",
      "Model aime_outputs/test2025-II/o4-mini-8-diverse on dataset test2025-II has score 0.8666666666666667\n",
      "Loading aime_outputs/test2025-II/gemini/Gemini_AIME_Dataset_2024_25_II.jsonl with 15 samples\n",
      "Pass@1:  13/15 = 0.8667\n",
      "Consensus (majority voting): 13/15 = 0.8667\n",
      "Pass@1: 13/15 = 0.8667\n",
      "Model aime_outputs/test2025-II/gemini on dataset test2025-II has score 0.8666666666666667\n",
      "Loading aime_outputs/test2025-I/o4-mini/AIME_o4_mini_8_traj_25_I.jsonl with 15 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass@1:  12/15 = 0.8000\n",
      "Consensus (majority voting): 12/15 = 0.8000\n",
      "Pass@1: 12/15 = 0.8000\n",
      "Model aime_outputs/test2025-I/o4-mini on dataset test2025-I has score 0.8\n",
      "Loading aime_outputs/test2025-I/o4-mini-8-diverse/AIME_o4_mini_diverse_traj_25_I.jsonl with 15 samples\n",
      "Pass@1:  11/15 = 0.7333\n",
      "Consensus (majority voting): 11/15 = 0.7333\n",
      "Pass@1: 11/15 = 0.7333\n",
      "Model aime_outputs/test2025-I/o4-mini-8-diverse on dataset test2025-I has score 0.7333333333333333\n",
      "Loading aime_outputs/test2025-I/gemini/Gemini_AIME_Dataset_2024_25_I.jsonl with 15 samples\n",
      "Pass@1:  13/15 = 0.8667\n",
      "Consensus (majority voting): 13/15 = 0.8667\n",
      "Pass@1: 13/15 = 0.8667\n",
      "Model aime_outputs/test2025-I/gemini on dataset test2025-I has score 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import eval_aime\n",
    "from eval_aime import eval\n",
    "import importlib\n",
    "### reload eval_aime module to ensure it has the latest changes\n",
    "importlib.reload(eval_aime)\n",
    "paths = \"aime_outputs/\"\n",
    "    \n",
    "dataloader_benchmark = {}\n",
    "prediction_history = {}\n",
    "for ds in os.listdir(paths):\n",
    "    dataloader_benchmark[ds] = {}\n",
    "    ds_ = os.path.join(paths, ds)\n",
    "    prediction_history[ds] = {}\n",
    "    \n",
    "    for model_out in os.listdir(ds_):\n",
    "        model_out = os.path.join(ds_, model_out)\n",
    "        path = os.listdir(model_out)[0]\n",
    "        path = os.path.join(model_out, path)\n",
    "        output = pd.read_json(path_or_buf=path, lines=True)\n",
    "        # if path!=\"aime_outputs/test2025-II/gemini/Gemini_AIME_Dataset_2024_25_II.jsonl\":\n",
    "        #     continue\n",
    "        print(f\"Loading {path} with {len(output)} samples\")\n",
    "        output[\"index\"] = output.index\n",
    "        output = output.explode([\"generated_responses\", \"answers_correctness\"]).reset_index(drop=True)\n",
    "        # sep = \"\\n\" if \"o4\" in model_out else \"\\n\\n\"\n",
    "        sep = \"\\n\\n\"\n",
    "        output[\"generated_responses\"] = output[\"generated_responses\"].apply(lambda x: x.split(sep))\n",
    "        output.rename(columns={\"generated_responses\": \"completions\"}, inplace=True)\n",
    "        output[\"labels\"] = [\n",
    "                    [val] * len(completions)\n",
    "                    for val, completions in zip(output[\"answers_correctness\"], output[\"completions\"])\n",
    "                ]\n",
    "        output[\"subject\"] = \"Others\" ## filler values\n",
    "        \n",
    "        all_problem_pred = []\n",
    "        for questions, solutions in zip(output['problem'].tolist(), output['completions'].tolist()):\n",
    "            step_rewards = evaluate_question_stepwise(\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                system_prompt=\"Please reason step by step, and put your final answer within \\\\boxed{}.\",\n",
    "                question=questions,\n",
    "                stepwise_solution=solutions\n",
    "            )\n",
    "\n",
    "            all_problem_pred+=[step_rewards[-1]]\n",
    "            \n",
    "        predictions, score = eval(output, all_problem_pred, ds)\n",
    "        print(f\"Model {model_out} on dataset {ds} has score {score}\")\n",
    "        prediction_history[ds][model_out] = predictions\n",
    "\n",
    "        \n",
    "        \n",
    "# import pickle\n",
    "# with open(\"aime_prediction_history.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(prediction_history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProcessBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ccbfee820e4a14b8b639869bd3f6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f3bcda772e48ceab990965f523614e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gsm8k.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe7a68f66454769a494a428e1a9a6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "math.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9c934b53734b4baf0ecaacdb70774e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "olympiadbench.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846c966963c14a27af432f2a83e53e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "omnimath.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48424efe4cb34292b1fb1731f9af9743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating gsm8k split:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8780c03391ee4649bab0b0729c820260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating math split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe22f96a10a941e8915ac5af6a07dc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating olympiadbench split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb41fb5596e14fda933a1ef9154e1033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating omnimath split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    gsm8k: Dataset({\n",
       "        features: ['id', 'generator', 'problem', 'steps', 'final_answer_correct', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "    math: Dataset({\n",
       "        features: ['id', 'generator', 'problem', 'steps', 'final_answer_correct', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    olympiadbench: Dataset({\n",
       "        features: ['id', 'generator', 'problem', 'steps', 'final_answer_correct', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    omnimath: Dataset({\n",
       "        features: ['id', 'generator', 'problem', 'steps', 'final_answer_correct', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "process_benchmark = load_dataset(\"Qwen/ProcessBench\")\n",
    "process_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generator</th>\n",
       "      <th>problem</th>\n",
       "      <th>steps</th>\n",
       "      <th>final_answer_correct</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>math-0</td>\n",
       "      <td>Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>Determine the remainder of 194 (mod 11).</td>\n",
       "      <td>[To determine the remainder of 194 (mod 11), I...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>math-1</td>\n",
       "      <td>Qwen2.5-Math-72B-Instruct</td>\n",
       "      <td>Find the real roots of\\n\\[\\frac{( x+ 1)(x - 3)...</td>\n",
       "      <td>[To solve the equation\\n\\[\\n\\frac{( x+ 1)(x - ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>math-2</td>\n",
       "      <td>Meta-Llama-3-70B-Instruct</td>\n",
       "      <td>Consider the two functions $f(x) = x^2 + 2bx +...</td>\n",
       "      <td>[We first solve for the values of \\(a\\) and \\(...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>math-3</td>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>Determine the remainder of 1529 (mod 6).</td>\n",
       "      <td>[To determine the remainder of 1529 (mod 6), w...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>math-4</td>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>The Coventry School's European debate club has...</td>\n",
       "      <td>[To find the total number of ways the delegate...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>math-995</td>\n",
       "      <td>Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>A square and a triangle have the same area. If...</td>\n",
       "      <td>[Let's break down the problem step by step: Fi...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>math-996</td>\n",
       "      <td>Qwen2.5-Math-7B-Instruct</td>\n",
       "      <td>Find the least common multiple of $6!$ and $(4...</td>\n",
       "      <td>[To find the least common multiple (LCM) of \\(...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>math-997</td>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>What simplified common fraction is equivalent ...</td>\n",
       "      <td>[To convert the repeating decimal \\(0.0\\overli...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>math-998</td>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>Stacy has $d$ dollars. She enters a mall with ...</td>\n",
       "      <td>[Let's break down the problem step by step to ...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>math-999</td>\n",
       "      <td>Qwen2-1.5B-Instruct</td>\n",
       "      <td>The number of toy cars that Ray has is a multi...</td>\n",
       "      <td>[To find the possible values of \\(n\\), we firs...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                  generator  ... final_answer_correct label\n",
       "0      math-0   Meta-Llama-3-8B-Instruct  ...                False     0\n",
       "1      math-1  Qwen2.5-Math-72B-Instruct  ...                False     9\n",
       "2      math-2  Meta-Llama-3-70B-Instruct  ...                False     3\n",
       "3      math-3      Llama-3.1-8B-Instruct  ...                False     1\n",
       "4      math-4      Llama-3.1-8B-Instruct  ...                False     2\n",
       "..        ...                        ...  ...                  ...   ...\n",
       "995  math-995   Meta-Llama-3-8B-Instruct  ...                 True    -1\n",
       "996  math-996   Qwen2.5-Math-7B-Instruct  ...                 True    -1\n",
       "997  math-997          Qwen2-7B-Instruct  ...                 True    -1\n",
       "998  math-998        Qwen2.5-7B-Instruct  ...                 True     5\n",
       "999  math-999        Qwen2-1.5B-Instruct  ...                 True     2\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = process_benchmark['math'].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frozenwolf/miniconda3/envs/prm/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/frozenwolf/miniconda3/envs/prm/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: gsm8k\n",
      "Number of samples: 400\n",
      "Problem-wise Metrics: {'TP': 105, 'FP': 93, 'TN': 107, 'FN': 95, 'Accuracy': 0.53, 'Precision': 0.5303030303030303, 'Recall': 0.525, 'F1': 0.5276381909547739}\n",
      "Dataset: math\n",
      "Number of samples: 1000\n",
      "Problem-wise Metrics: {'TP': 253, 'FP': 263, 'TN': 237, 'FN': 247, 'Accuracy': 0.49, 'Precision': 0.4903100775193798, 'Recall': 0.506, 'F1': 0.4980314960629921}\n",
      "Dataset: olympiadbench\n",
      "Number of samples: 1000\n",
      "Problem-wise Metrics: {'TP': 249, 'FP': 233, 'TN': 267, 'FN': 251, 'Accuracy': 0.516, 'Precision': 0.516597510373444, 'Recall': 0.498, 'F1': 0.5071283095723014}\n",
      "Dataset: omnimath\n",
      "Number of samples: 1000\n",
      "Problem-wise Metrics: {'TP': 251, 'FP': 238, 'TN': 262, 'FN': 249, 'Accuracy': 0.513, 'Precision': 0.5132924335378323, 'Recall': 0.502, 'F1': 0.5075834175935288}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from model import binary_classification_metrics\n",
    "\n",
    "\n",
    "history = {}\n",
    "for dataset in process_benchmark:\n",
    "    history[dataset] = {}\n",
    "    all_problem_correctness = []\n",
    "    all_problem_pred = []\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    df = process_benchmark[dataset].to_pandas()\n",
    "    print(f\"Number of samples: {len(df)}\")\n",
    "    for problem, step, correctness in zip(df['problem'], df['steps'], df['final_answer_correct']):\n",
    "        step_rewards = evaluate_question_stepwise(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        system_prompt=\"Please reason step by step, and put your final answer within \\\\boxed{}.\",\n",
    "        question=problem,\n",
    "        stepwise_solution=step\n",
    "    )\n",
    "\n",
    "        all_problem_correctness+=[correctness]\n",
    "        a = step_rewards[-1]\n",
    "        all_problem_pred+=[1 if a>=0.5 else 0]\n",
    "\n",
    "        history[dataset][problem] = {\n",
    "            \"step_rewards\": step_rewards,\n",
    "            \"correctness\": correctness,\n",
    "            \"predicted_correctness\": a\n",
    "        }\n",
    "        \n",
    "    problem_metric = binary_classification_metrics(all_problem_pred, all_problem_correctness)\n",
    "\n",
    "    print(\"Problem-wise Metrics:\", problem_metric)\n",
    "    \n",
    "import pickle\n",
    "with open(\"process_benchmark_history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRM800K'test set (10 questions sampled per subject) Step-wise & Problem-wise Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric Type</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step-wise</td>\n",
       "      <td>2079</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>116</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Problem-wise</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.4923</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.5517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metric Type    TP  FP  TN   FN  Accuracy  Precision  Recall      F1\n",
       "0     Step-wise  2079  42  50  116    0.9309     0.9802  0.9472  0.9634\n",
       "1  Problem-wise    32  33  37   19    0.5702     0.4923  0.6275  0.5517"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process bench: Problem-wise Metrics by Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>math</td>\n",
       "      <td>199</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.5905</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.7412</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>olympiadbench</td>\n",
       "      <td>476</td>\n",
       "      <td>296</td>\n",
       "      <td>204</td>\n",
       "      <td>24</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.6166</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.7484</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omnimath</td>\n",
       "      <td>474</td>\n",
       "      <td>360</td>\n",
       "      <td>140</td>\n",
       "      <td>26</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.7106</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>omnimath (2)</td>\n",
       "      <td>456</td>\n",
       "      <td>367</td>\n",
       "      <td>133</td>\n",
       "      <td>44</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>0.5541</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset   TP   FP   TN  ...  Precision  Recall      F1  Samples\n",
       "0           math  199  138   62  ...     0.5905   0.995  0.7412     1000\n",
       "1  olympiadbench  476  296  204  ...     0.6166   0.952  0.7484     1000\n",
       "2       omnimath  474  360  140  ...     0.5683   0.948  0.7106     1000\n",
       "3   omnimath (2)  456  367  133  ...     0.5541   0.912  0.6893     1000\n",
       "\n",
       "[4 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step-wise & Problem-wise Metrics (General)\n",
    "step_problem_metrics = pd.DataFrame([\n",
    "    {\"Metric Type\": \"Step-wise\", \"TP\": 2079, \"FP\": 42, \"TN\": 50, \"FN\": 116,\n",
    "     \"Accuracy\": 0.9309, \"Precision\": 0.9802, \"Recall\": 0.9472, \"F1\": 0.9634},\n",
    "    {\"Metric Type\": \"Problem-wise\", \"TP\": 32, \"FP\": 33, \"TN\": 37, \"FN\": 19,\n",
    "     \"Accuracy\": 0.5702, \"Precision\": 0.4923, \"Recall\": 0.6275, \"F1\": 0.5517}\n",
    "])\n",
    "\n",
    "# AIME Dataset Evaluation Summary\n",
    "aime_eval = pd.DataFrame([\n",
    "    {\"Model Variant\": \"o4-mini\", \"Dataset\": \"test2025-I\", \"Pass@1\": 0.8000, \"Consensus\": 0.0667, \"Score\": 0.1616},\n",
    "    {\"Model Variant\": \"o4-mini-8-diverse\", \"Dataset\": \"test2025-I\", \"Pass@1\": 0.7333, \"Consensus\": 0.7333, \"Score\": 0.7333},\n",
    "    {\"Model Variant\": \"o4-mini\", \"Dataset\": \"test2025-II\", \"Pass@1\": 0.9333, \"Consensus\": 0.8667, \"Score\": 0.2500},\n",
    "    {\"Model Variant\": \"o4-mini-8-diverse\", \"Dataset\": \"test2025-II\", \"Pass@1\": 0.8667, \"Consensus\": 0.8000, \"Score\": 0.5000}\n",
    "])\n",
    "\n",
    "# Problem-wise Metrics by Dataset\n",
    "dataset_metrics = pd.DataFrame([\n",
    "    {\"Dataset\": \"math\", \"TP\": 199, \"FP\": 138, \"TN\": 62, \"FN\": 1,\n",
    "     \"Accuracy\": 0.6525, \"Precision\": 0.5905, \"Recall\": 0.995, \"F1\": 0.7412, \"Samples\": 1000},\n",
    "    {\"Dataset\": \"olympiadbench\", \"TP\": 476, \"FP\": 296, \"TN\": 204, \"FN\": 24,\n",
    "     \"Accuracy\": 0.6800, \"Precision\": 0.6166, \"Recall\": 0.952, \"F1\": 0.7484, \"Samples\": 1000},\n",
    "    {\"Dataset\": \"omnimath\", \"TP\": 474, \"FP\": 360, \"TN\": 140, \"FN\": 26,\n",
    "     \"Accuracy\": 0.6140, \"Precision\": 0.5683, \"Recall\": 0.948, \"F1\": 0.7106, \"Samples\": 1000},\n",
    "    {\"Dataset\": \"omnimath (2)\", \"TP\": 456, \"FP\": 367, \"TN\": 133, \"FN\": 44,\n",
    "     \"Accuracy\": 0.5890, \"Precision\": 0.5541, \"Recall\": 0.912, \"F1\": 0.6893, \"Samples\": 1000}\n",
    "])\n",
    "\n",
    "# Print them\n",
    "print(\"PRM800K'test set (10 questions sampled per subject) Step-wise & Problem-wise Metrics:\")\n",
    "display(step_problem_metrics)\n",
    "# print(\"\\nAIME Evaluation Summary:\")\n",
    "# display(aime_eval)\n",
    "print(\"\\nProcess bench: Problem-wise Metrics by Dataset:\")\n",
    "display(dataset_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIME_o4_mini_8_traj_25_I.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ls aime_outputs/test2025-I/o4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"aime_outputs/test2025-I/gemini/Gemini_AIME_Dataset_2024_25_I.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_json(\"aime_outputs/test2025-I/o4-mini/AIME_o4_mini_8_traj_25_I.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "prm = load_dataset(\"FrozenWolf/prm800k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completions</th>\n",
       "      <th>labels</th>\n",
       "      <th>index</th>\n",
       "      <th>correctness</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>level</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many positive two-digit integers leave a r...</td>\n",
       "      <td>[So if a number leaves a remainder of 2 when d...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Number Theory</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326762</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[To find the greatest common divisor, we need ...</td>\n",
       "      <td>[False]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326763</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[Let's write out the prime factorization of 12.]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326764</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[Let's write the prime factorization for each ...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326765</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[Let's prime factorize 12. 12 is divisible by ...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326766</th>\n",
       "      <td>Find the greatest common divisor of 12 and 20.</td>\n",
       "      <td>[Ok, well let's first find the prime factoriza...</td>\n",
       "      <td>[True]</td>\n",
       "      <td>97732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Prealgebra</td>\n",
       "      <td>2</td>\n",
       "      <td>327697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326767 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   prompt  ... __index_level_0__\n",
       "0       How many positive two-digit integers leave a r...  ...                 0\n",
       "1       How many positive two-digit integers leave a r...  ...                 1\n",
       "2       How many positive two-digit integers leave a r...  ...                 2\n",
       "3       How many positive two-digit integers leave a r...  ...                 3\n",
       "4       How many positive two-digit integers leave a r...  ...                 4\n",
       "...                                                   ...  ...               ...\n",
       "326762     Find the greatest common divisor of 12 and 20.  ...            327693\n",
       "326763     Find the greatest common divisor of 12 and 20.  ...            327694\n",
       "326764     Find the greatest common divisor of 12 and 20.  ...            327695\n",
       "326765     Find the greatest common divisor of 12 and 20.  ...            327696\n",
       "326766     Find the greatest common divisor of 12 and 20.  ...            327697\n",
       "\n",
       "[326767 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prm['train'].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in df['labels'].tolist():\n",
    "    labels+=i.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 1772685, False: 199062})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(labels)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10095717148295395"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "199062/(1772685+199062)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
